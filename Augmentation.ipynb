{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive if using it\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7dbFbonvBaP","outputId":"e9d2cf3d-4739-4506-fa99-decea6e5c595","executionInfo":{"status":"ok","timestamp":1748961900442,"user_tz":-360,"elapsed":34622,"user":{"displayName":"nuha rabbani","userId":"08842261684687353679"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# prompt: pip tensorflow.keras.preprocessing.image\n","\n","!pip install tensorflow\n","\n","import tensorflow as tf"],"metadata":{"id":"aSe9T6_rvIEw","executionInfo":{"status":"ok","timestamp":1748961930533,"user_tz":-360,"elapsed":10807,"user":{"displayName":"nuha rabbani","userId":"08842261684687353679"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb52b53f-4f22-49ca-85c7-eb67ac567965"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0An_HveFt4lW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fccf7c7-94c7-42cd-a64f-f3c1597528bc","executionInfo":{"status":"ok","timestamp":1748963106017,"user_tz":-360,"elapsed":1175480,"user":{"displayName":"nuha rabbani","userId":"08842261684687353679"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting image augmentation process...\n","Input folder: /content/drive/MyDrive/MiniketRice/Dataset/Black_Background\n","Output folder: /content/drive/MyDrive/MiniketRice/Dataset/Augmented_Miniket_Rice\n","Found 10 categories: ['Katari Najir', 'Aaush', 'Sorna', 'Miniket', 'Katari Siddho', 'Ghee Vogh', 'Chinigura', 'BR-29(hasaki)', 'BR-28', 'Beroi']\n","\n","[1/10] Processing category: Katari Najir\n","Processing category: Katari Najir\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed Katari Najir: 200 images processed, 800 augmented images created\n","\n","[2/10] Processing category: Aaush\n","Processing category: Aaush\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed Aaush: 200 images processed, 800 augmented images created\n","\n","[3/10] Processing category: Sorna\n","Processing category: Sorna\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed Sorna: 200 images processed, 800 augmented images created\n","\n","[4/10] Processing category: Miniket\n","Processing category: Miniket\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed Miniket: 200 images processed, 800 augmented images created\n","\n","[5/10] Processing category: Katari Siddho\n","Processing category: Katari Siddho\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed Katari Siddho: 200 images processed, 800 augmented images created\n","\n","[6/10] Processing category: Ghee Vogh\n","Processing category: Ghee Vogh\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed Ghee Vogh: 200 images processed, 800 augmented images created\n","\n","[7/10] Processing category: Chinigura\n","Processing category: Chinigura\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed Chinigura: 200 images processed, 800 augmented images created\n","\n","[8/10] Processing category: BR-29(hasaki)\n","Processing category: BR-29(hasaki)\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed BR-29(hasaki): 200 images processed, 800 augmented images created\n","\n","[9/10] Processing category: BR-28\n","Processing category: BR-28\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed BR-28: 200 images processed, 800 augmented images created\n","\n","[10/10] Processing category: Beroi\n","Processing category: Beroi\n","  Processed 10/200 images...\n","  Processed 20/200 images...\n","  Processed 30/200 images...\n","  Processed 40/200 images...\n","  Processed 50/200 images...\n","  Processed 60/200 images...\n","  Processed 70/200 images...\n","  Processed 80/200 images...\n","  Processed 90/200 images...\n","  Processed 100/200 images...\n","  Processed 110/200 images...\n","  Processed 120/200 images...\n","  Processed 130/200 images...\n","  Processed 140/200 images...\n","  Processed 150/200 images...\n","  Processed 160/200 images...\n","  Processed 170/200 images...\n","  Processed 180/200 images...\n","  Processed 190/200 images...\n","  Processed 200/200 images...\n","  Completed Beroi: 200 images processed, 800 augmented images created\n","\n","==================================================\n","Augmentation completed successfully!\n","Augmented images saved to: /content/drive/MyDrive/MiniketRice/Dataset/Augmented_Miniket_Rice\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Paths\n","input_folder = '/content/drive/MyDrive/MiniketRice/Dataset/Black_Background'\n","output_base_folder = '/content/drive/MyDrive/MiniketRice/Dataset/Augmented_Miniket_Rice'\n","os.makedirs(output_base_folder, exist_ok=True)\n","\n","# Data augmentation setup\n","datagen = ImageDataGenerator(\n","    rotation_range=30,          # Rotate images by up to 30 degrees\n","    shear_range=0.2,           # Shear transformation\n","    vertical_flip=True,        # Randomly flip images vertically\n","    horizontal_flip=True,      # Randomly flip images horizontally\n","    width_shift_range=0.1,     # Randomly shift images horizontally\n","    height_shift_range=0.1,    # Randomly shift images vertically\n","    zoom_range=0.1,            # Random zoom\n","    brightness_range=[0.8, 1.2] # Random brightness adjustment\n",")\n","\n","def augment_images_for_category(category_name, category_folder, output_base_folder, num_augmentations=4):\n","    \"\"\"\n","    Augment images for a specific category\n","\n","    Args:\n","        category_name: Name of the category (folder name)\n","        category_folder: Path to the category folder containing images\n","        output_base_folder: Base output folder for augmented images\n","        num_augmentations: Number of augmented versions to create per image\n","    \"\"\"\n","    # Create a folder for this category in the output folder\n","    category_output_folder = os.path.join(output_base_folder, category_name)\n","    os.makedirs(category_output_folder, exist_ok=True)\n","\n","    print(f\"Processing category: {category_name}\")\n","\n","    # Get list of image files (filter by common image extensions)\n","    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n","    image_files = [f for f in os.listdir(category_folder)\n","                   if os.path.splitext(f.lower())[1] in image_extensions]\n","\n","    processed_count = 0\n","    total_images = len(image_files)\n","\n","    # Process all images in the category folder\n","    for filename in image_files:\n","        file_path = os.path.join(category_folder, filename)\n","        try:\n","            # Read the image\n","            img = cv2.imread(file_path)\n","            if img is None:\n","                print(f\"  Skipping unreadable image: {filename}\")\n","                continue\n","\n","            # Convert BGR to RGB for ImageDataGenerator\n","            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            img_array = img_rgb.reshape((1,) + img_rgb.shape)  # Shape as required by datagen.flow\n","\n","            # Create the augmentation generator\n","            aug_iter = datagen.flow(img_array, batch_size=1)\n","\n","            # Save exactly `num_augmentations` augmentations\n","            base_name = os.path.splitext(filename)[0]\n","            for i in range(num_augmentations):\n","                augmented_img = next(aug_iter)[0].astype('uint8')\n","                augmented_img_path = os.path.join(category_output_folder, f\"{base_name}_aug_{i + 1}.jpg\")\n","\n","                # Convert back to BGR for OpenCV saving\n","                augmented_img_bgr = cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR)\n","                cv2.imwrite(augmented_img_path, augmented_img_bgr)\n","\n","            processed_count += 1\n","            if processed_count % 10 == 0:\n","                print(f\"  Processed {processed_count}/{total_images} images...\")\n","\n","        except Exception as e:\n","            print(f\"  Error processing {filename}: {e}\")\n","\n","    print(f\"  Completed {category_name}: {processed_count} images processed, {processed_count * num_augmentations} augmented images created\")\n","\n","def main():\n","    \"\"\"Main function to process all categories\"\"\"\n","    print(\"Starting image augmentation process...\")\n","    print(f\"Input folder: {input_folder}\")\n","    print(f\"Output folder: {output_base_folder}\")\n","\n","    if not os.path.exists(input_folder):\n","        print(f\"Error: Input folder does not exist: {input_folder}\")\n","        return\n","\n","    # Get all category folders\n","    categories = [d for d in os.listdir(input_folder)\n","                  if os.path.isdir(os.path.join(input_folder, d))]\n","\n","    if not categories:\n","        print(\"No category folders found in the input directory!\")\n","        return\n","\n","    print(f\"Found {len(categories)} categories: {categories}\")\n","\n","    total_categories = len(categories)\n","    for idx, category_name in enumerate(categories, 1):\n","        category_folder = os.path.join(input_folder, category_name)\n","        print(f\"\\n[{idx}/{total_categories}] Processing category: {category_name}\")\n","        augment_images_for_category(category_name, category_folder, output_base_folder)\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"Augmentation completed successfully!\")\n","    print(f\"Augmented images saved to: {output_base_folder}\")\n","\n","# Run the main function\n","if __name__ == \"__main__\":\n","    main()"]}]}